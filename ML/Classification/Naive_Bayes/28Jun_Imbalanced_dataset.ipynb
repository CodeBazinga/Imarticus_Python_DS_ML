{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944d545e",
   "metadata": {},
   "source": [
    "### Imbalanced Data\n",
    "1) When observation in one class is severely higher than the observations in other class/(es) then there exists a class imbalance. This problem is referred to as Imbalanced data problem.\n",
    "\n",
    "2) When there is severe skewness in the class distribution such as 80:20 majority to minority class ratio or beyond then there exists class imbalance. \n",
    "\n",
    "3) The high bias in the data can heavily affect many ML algorithms completely ignoring the minority class. The problem statements concerning imbalanced data are usually the ones where predictions on minority class are considered significant.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a2eab7",
   "metadata": {},
   "source": [
    "### Handling Imbalanced Data: Best Practices and Approaches\n",
    "1) <b>Collect More Data:</b><br>\n",
    "A larger dataset might expose a different and perhaps more balanced perspective on the classes.\n",
    "\n",
    "2) <b>Try Changing Your Performance Metric:</b><br>\n",
    "Accuracy is not the metric to use when working with an imbalanced dataset. \n",
    "\n",
    "Looking at the following performance measures that can give more insight into the accuracy of the model than traditional classification accuracy:\n",
    "\n",
    "a) <b>Confusion Matrix:</b> A breakdown of predictions into a table showing correct predictions (the diagonal) and the types of incorrect predictions made (what classes incorrect predictions were assigned).<br>\n",
    "b) <b>Precision:</b> <br>\n",
    "c) <b>Recall:</b><br>\n",
    "d) <b>F1 Score (or F-score):</b> A weighted average of precision and recall.<br>\n",
    "e) <b>Adjust the decision threshold (ROC, AUC)</b>\n",
    "\n",
    "\n",
    "3) <b>Boosting Algorithm</b><br>\n",
    "XGBoost: xgboost offers parameters to balance positive and negative weights using scale_pos_weight\n",
    "\n",
    "4) <b>Weighting of examples</b><br>\n",
    "It involves the creation of specific weight vectors in order to improve minority class predictions.\n",
    "\n",
    "The class-specific weights(class_weight parameter) are calculated per class whereas the test-case-specific weights are calculated for each single instance.\n",
    "\n",
    "5) <b>Use Stratified CV</b><br>\n",
    "\n",
    "6) <b>Penalized SVM</b><br>\n",
    "In SVM where it is desired to give more importance to certain classes or certain individual samples, the parameters class_weight and sample_weight can be used.\n",
    "\n",
    "7) <b>Data Level approach</b><br>\n",
    "We can perform undersampling or oversampling<br>\n",
    "\n",
    "a) <b>Under_Sampling</b><br>\n",
    "Undersampling techniques refer to remove majority class points. Some oversampling techniques are ENN, Random Under Sampling, TomekLinks, etc.\n",
    "\n",
    "b) <b>OverSampling</b><br>\n",
    "Oversampling techniques refer to create artificial minority class points. Some oversampling techniques are Random Over Sampling, ADASYN, SMOTE, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8e038f",
   "metadata": {},
   "source": [
    "### Install imblearn\n",
    "\n",
    "1) In Anaconda prompt, write the follwing<br>\n",
    "<b>conda install -c conda-forge imbalanced-learn</b>\n",
    "\n",
    "2) In CMD<br>\n",
    "<b>pip install imblearn</b>\n",
    "\n",
    "3) In Jupyter<br>\n",
    "<b>!pip install imblearn</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2312cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00ced8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.metrics import roc_curve,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3cd4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_metrics(model,x_train,x_test,y_train,y_test):\n",
    "    model.fit(x_train,y_train)\n",
    "    train_score = model.score(x_train,y_train)\n",
    "    test_score = model.score(x_test,y_test)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print('Predictions\\n',y_pred)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    print('Training score',train_score)\n",
    "    print('Testing score',test_score)\n",
    "    print('Accuracy_Score',acc)\n",
    "    cm = confusion_matrix(y_test,y_pred)\n",
    "    print('Confusion Matrix\\n',cm)\n",
    "    print('Classification Report\\n',classification_report(y_test,y_pred))\n",
    "    auc_score  = roc_auc_score(y_test,model.predict_proba(x_test)[:,1])\n",
    "    print('AUC Score',auc_score)\n",
    "    fpr,tpr,thresh = roc_curve(y_test,model.predict_proba(x_test)[:,1])\n",
    "    plt.plot(fpr,tpr,color='blue')\n",
    "    plt.plot([0,1],[0,1],label='TPR=FPR',linestyle=':',color='black')\n",
    "    plt.title('ROC_AUC Curve')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.legend(loc=8)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb08c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8411e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = make_classification(n_samples=1000,n_features=2,n_redundant=0,\n",
    "                          weights=[0.9,0.1],n_classes=2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0182f0da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde1673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b63b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc6f5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7adbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e43ed74e",
   "metadata": {},
   "source": [
    "### OverSampling\n",
    "<img src=\"oversampling.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c21c7e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c483097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc09b24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfbfe23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db96db0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b84549c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9387ec2",
   "metadata": {},
   "source": [
    "### UnderSampling\n",
    "\n",
    "<img src=\"undersampling.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4dcb348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e785b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc28df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb5fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a1c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af9b737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb12514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bde02a6",
   "metadata": {},
   "source": [
    "### SMOTE (Synthetic Minority OverSampling Technique)\n",
    "\n",
    "1) Unlike random oversampling that only duplicates some random examples from the minority class, SMOTE generates examples based on the distance of each data (usually using Euclidean distance) and the minority class nearest neighbors, so the generated examples are different from the original minority class.<br>\n",
    "2)  Steps in SMOTE\n",
    "\n",
    "    a) Identify the minority class vector.\n",
    "    b) Decide the number of nearest numbers (k), to consider.\n",
    "    c) Compute a line between the minority data points and any of its neighbors and place a synthetic  point.\n",
    "    4) Repeat step 3 for all minority data points and their k neighbors, till the data is balanced.\n",
    "\n",
    "<img src=\"smote2.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b0572444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d52703b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be6b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005c8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a804c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a98d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d608df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17ff0a37",
   "metadata": {},
   "source": [
    "#### Is it better to Undersample or OverSample?\n",
    "\n",
    "Oversampling is better, because you keep all the information in the training dataset. With undersampling you drop a lot of information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5160b87d",
   "metadata": {},
   "source": [
    "### Other Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41ecae9",
   "metadata": {},
   "source": [
    "#### ADASYN (Adaptive Synthetic Sampling)\n",
    "1) It is an oversampling technique<br>\n",
    "2) Generate more synthetic examples in regions of the feature space where the density of minority examples is low, and fewer or none where the density is high.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27688bc",
   "metadata": {},
   "source": [
    "#### BorderLineSMOTE\n",
    "1) This algorithm starts by classifying the minority class observations. It classifies any minority observation as a noise point if all the neighbors are the majority class and such an observation is ignored while creating synthetic data.<br>\n",
    "2) It classifies a few points as border points that have both majority and minority class as neighborhood and resample completely from these points (Extreme observations on which a support vector will typically pay attention to)\n",
    "\n",
    "<img src=\"borderline_smote.png\" align=\"left\" height=\"350\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a841a42",
   "metadata": {},
   "source": [
    "#### TomekLinks\n",
    "1) Tomek Links is an undersampling approach that identifies all the pairs of data points that are nearest to each other but belong to different classes, and these pairs (suppose a and b) are termed as Tomek links. Tomek Links follows these conditions:\n",
    "\n",
    "    a and b are nearest neighbors of each other\n",
    "    a and b belong to two different classes\n",
    "    \n",
    "2) These Tomek links points (a, b) are present on the boundary of separation of the two classes. So removing the majority class of Tomek links points increases the class separation, and also reduces the number of majority class samples along the boundary of the majority cluster.\n",
    "<img src=\"tomek_links.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd98c9f",
   "metadata": {},
   "source": [
    "#### SMOTETOMEK\n",
    "A hybrid method which is a mixture of the above two methods, it uses an under-sampling method (Tomek) with an oversampling method (SMOTE). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d14d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN, BorderlineSMOTE\n",
    "from imblearn.under_sampling import TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e52c223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek,SMOTEENN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
